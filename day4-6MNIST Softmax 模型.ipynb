{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0.9199\n"
     ]
    }
   ],
   "source": [
    "# https://ithelp.ithome.com.tw/articles/1018687\n",
    "# 實作 MNIST Softmax 模型\n",
    "\n",
    "# 目標\n",
    "# 1實作 Softmax Regressions\n",
    "# 2了解 tensorflow computation graph\n",
    "\n",
    "import tensorflow as tf\n",
    "#讀mnist\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "\n",
    "#操作符號變數來描述這一些交互操\n",
    "#範例\n",
    "#x 不是一個特定的數值．他是一個佔位子 (placeholder)\n",
    "#預先保留的數值，在真正計算的時候才把數值輸入進去\n",
    "#我們想要可以輸入任意數量的 MNIST 圖片\n",
    "#每一張圖都會先轉化成 784 維的向量．\n",
    "#用 2-D 的浮點數 tensor 來表現它\n",
    "#None 意味著它第一個維度可以是任一長度的\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "\n",
    "W = tf.Variable( tf.zeros([784,10]) )\n",
    "b = tf.Variable( tf.zeros([10]) )\n",
    "\n",
    "#softmax 回歸\n",
    "#例如在郵件分類問題中，我們要把郵件分為垃圾郵件、個人郵件、工作郵件3類，目標值y是一個有3個取值的離散值。這是一個多分類問題\n",
    "#目的是辨識10個不同的單個數字\n",
    "y = tf.nn.softmax( tf.matmul(x,W) +b )\n",
    "\n",
    "#模型訓練\n",
    "#在機器學習中，通常是定義一個模型怎樣算是不好的\n",
    "#這個定義稱作成本 (cost) 或是損失 (loss)，\n",
    "#它代表我們的模型和預期的結果間的差距\n",
    "#要最小化這些成本，成本或損失越低代表模型越好．\n",
    "#常見成本函數稱作 cross-entropy\n",
    "#y 是預測的機率分佈，\n",
    "#而 y' 是真實的機率分佈 (one-hot 數字向量)\n",
    "#cross-entropy 用來量測我們的預測和真實之間的差距\n",
    "\n",
    "#放置正確的答案\n",
    "#cross_entroy定義 -sum(yi' *log(yi))\n",
    "y_ = tf.placeholder( tf.float32, [None,10])\n",
    "cross_entropy = tf.reduce_mean( -tf.reduce_sum(y_*tf.log(y),reduction_indices=[1]))\n",
    "\n",
    "# 使用梯度下降法 gradient descent algorithm 來最小化 cross_entropy\n",
    "#learning rate 是 0.5\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "#執行\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "#執行1000次\n",
    "for i in range(1000):\n",
    "    #從訓練數據中隨機抓取一批 100 筆數據\n",
    "    #替換掉之前我們設定的位子 placeholder進行訓練\n",
    "    #mnist真實的資料\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    \n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_ :batch_ys})\n",
    "\n",
    "#評估模型\n",
    "#tf.argmax 可以讓我們找到在某一維的 tensor 中\n",
    "#找到最大的數值的索引值 (index)\n",
    "#tf.equal比對\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "#列出了一系列的布林值\n",
    "#布林值轉化成浮點數然後取平均\n",
    "#tf.cast(x輸入, dtype轉換目標類型, name=None名稱)類型轉換函數\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#印出測試資料執行的準確度\n",
    "print( sess.run(accuracy,feed_dict = {\n",
    "    x: mnist.test.images, y_:mnist.test.labels  \n",
    "}))\n",
    "\n",
    "\n",
    "#print(sess.run(W))\n",
    "#print(W.shape)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
